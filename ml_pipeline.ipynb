{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "!pip install pyarrow\n",
    "!pip install spacy\n",
    "!pip install pandarallel\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/commit_messages.parquet\n",
      "./data/commit_messages_with_label.parquet\n",
      "... ./data/labeled_commit_message_train.parquet\n",
      "... ./data/labeled_commit_message_dev.parquet\n",
      "... ./data/labeled_commit_message_test.parquet\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/\"\n",
    "data_path = os.path.join(data_dir, \"commit_messages.parquet\")\n",
    "tagged_data_path = os.path.join(data_dir, \"commit_messages_with_label.parquet\")\n",
    "tagged_trainset_path = os.path.join(data_dir, \"labeled_commit_message_train.parquet\")\n",
    "tagged_devset_path = os.path.join(data_dir, \"labeled_commit_message_dev.parquet\")\n",
    "tagged_testset_path = os.path.join(data_dir, \"labeled_commit_message_test.parquet\")\n",
    "print(data_path)\n",
    "print(tagged_data_path)\n",
    "print(\"...\", tagged_trainset_path)\n",
    "print(\"...\", tagged_devset_path)\n",
    "print(\"...\", tagged_testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562500, 11) (187500, 11) (250000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>first_segment_message</th>\n",
       "      <th>identifier</th>\n",
       "      <th>length_ok</th>\n",
       "      <th>capital_first_token</th>\n",
       "      <th>not_period_end</th>\n",
       "      <th>imperative_mood</th>\n",
       "      <th>good_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magenik</td>\n",
       "      <td>1421858642</td>\n",
       "      <td>Timeline update</td>\n",
       "      <td>Timeline update\\n</td>\n",
       "      <td>Timeline update\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polytomous</td>\n",
       "      <td>1509246803</td>\n",
       "      <td>Extract parameter on breakCurrentBlock TF2John</td>\n",
       "      <td>Extract parameter on breakCurrentBlock TF2John\\n</td>\n",
       "      <td>Extract parameter on breakCurrentBlock TF2John\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mero</td>\n",
       "      <td>1348444108</td>\n",
       "      <td>updated changelog</td>\n",
       "      <td>updated changelog\\n</td>\n",
       "      <td>updated changelog\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YominCarr</td>\n",
       "      <td>1414094992</td>\n",
       "      <td>Cleanup</td>\n",
       "      <td>Cleanup\\n</td>\n",
       "      <td>Cleanup\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Fuentes</td>\n",
       "      <td>1556550569</td>\n",
       "      <td>[maint] Updating copyright</td>\n",
       "      <td>[maint] Updating copyright\\n</td>\n",
       "      <td>[maint] Updating copyright\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    time_sec  \\\n",
       "0          Magenik  1421858642   \n",
       "1       polytomous  1509246803   \n",
       "2             mero  1348444108   \n",
       "3        YominCarr  1414094992   \n",
       "4  Anthony Fuentes  1556550569   \n",
       "\n",
       "                                          subject  \\\n",
       "0                                 Timeline update   \n",
       "1  Extract parameter on breakCurrentBlock TF2John   \n",
       "2                               updated changelog   \n",
       "3                                         Cleanup   \n",
       "4                      [maint] Updating copyright   \n",
       "\n",
       "                                            message  \\\n",
       "0                                 Timeline update\\n   \n",
       "1  Extract parameter on breakCurrentBlock TF2John\\n   \n",
       "2                               updated changelog\\n   \n",
       "3                                         Cleanup\\n   \n",
       "4                      [maint] Updating copyright\\n   \n",
       "\n",
       "                              first_segment_message  identifier  length_ok  \\\n",
       "0                                 Timeline update\\n        True       True   \n",
       "1  Extract parameter on breakCurrentBlock TF2John\\n       False       True   \n",
       "2                               updated changelog\\n        True       True   \n",
       "3                                         Cleanup\\n       False       True   \n",
       "4                      [maint] Updating copyright\\n        True       True   \n",
       "\n",
       "   capital_first_token  not_period_end  imperative_mood  good_message  \n",
       "0                 True            True            False         False  \n",
       "1                 True            True             True         False  \n",
       "2                False            True             True         False  \n",
       "3                 True            True            False         False  \n",
       "4                False            True             True         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = pd.read_parquet(tagged_trainset_path)\n",
    "dev_set = pd.read_parquet(tagged_devset_path)\n",
    "test_set = pd.read_parquet(tagged_testset_path)\n",
    "print(train_set.shape, dev_set.shape, test_set.shape)\n",
    "display(train_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (Training Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/commit_messages.parquet\n",
      "./data/commit_messages_with_label.parquet\n",
      "... ./data/labeled_commit_message_train.parquet\n",
      "... ./data/labeled_commit_message_dev.parquet\n",
      "... ./data/labeled_commit_message_test.parquet\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/\"\n",
    "data_path = os.path.join(data_dir, \"commit_messages.parquet\")\n",
    "tagged_data_path = os.path.join(data_dir, \"commit_messages_with_label.parquet\")\n",
    "tagged_trainset_path = os.path.join(data_dir, \"labeled_commit_message_train.parquet\")\n",
    "tagged_devset_path = os.path.join(data_dir, \"labeled_commit_message_dev.parquet\")\n",
    "tagged_testset_path = os.path.join(data_dir, \"labeled_commit_message_test.parquet\")\n",
    "print(data_path)\n",
    "print(tagged_data_path)\n",
    "print(\"...\", tagged_trainset_path)\n",
    "print(\"...\", tagged_devset_path)\n",
    "print(\"...\", tagged_testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562500, 11) (187500, 11) (250000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>first_segment_message</th>\n",
       "      <th>identifier</th>\n",
       "      <th>length_ok</th>\n",
       "      <th>capital_first_token</th>\n",
       "      <th>not_period_end</th>\n",
       "      <th>imperative_mood</th>\n",
       "      <th>good_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magenik</td>\n",
       "      <td>1421858642</td>\n",
       "      <td>Timeline update</td>\n",
       "      <td>Timeline update\\n</td>\n",
       "      <td>Timeline update\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polytomous</td>\n",
       "      <td>1509246803</td>\n",
       "      <td>Extract parameter on breakCurrentBlock TF2John</td>\n",
       "      <td>Extract parameter on breakCurrentBlock TF2John\\n</td>\n",
       "      <td>Extract parameter on breakCurrentBlock TF2John\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mero</td>\n",
       "      <td>1348444108</td>\n",
       "      <td>updated changelog</td>\n",
       "      <td>updated changelog\\n</td>\n",
       "      <td>updated changelog\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YominCarr</td>\n",
       "      <td>1414094992</td>\n",
       "      <td>Cleanup</td>\n",
       "      <td>Cleanup\\n</td>\n",
       "      <td>Cleanup\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Fuentes</td>\n",
       "      <td>1556550569</td>\n",
       "      <td>[maint] Updating copyright</td>\n",
       "      <td>[maint] Updating copyright\\n</td>\n",
       "      <td>[maint] Updating copyright\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    time_sec  \\\n",
       "0          Magenik  1421858642   \n",
       "1       polytomous  1509246803   \n",
       "2             mero  1348444108   \n",
       "3        YominCarr  1414094992   \n",
       "4  Anthony Fuentes  1556550569   \n",
       "\n",
       "                                          subject  \\\n",
       "0                                 Timeline update   \n",
       "1  Extract parameter on breakCurrentBlock TF2John   \n",
       "2                               updated changelog   \n",
       "3                                         Cleanup   \n",
       "4                      [maint] Updating copyright   \n",
       "\n",
       "                                            message  \\\n",
       "0                                 Timeline update\\n   \n",
       "1  Extract parameter on breakCurrentBlock TF2John\\n   \n",
       "2                               updated changelog\\n   \n",
       "3                                         Cleanup\\n   \n",
       "4                      [maint] Updating copyright\\n   \n",
       "\n",
       "                              first_segment_message  identifier  length_ok  \\\n",
       "0                                 Timeline update\\n        True       True   \n",
       "1  Extract parameter on breakCurrentBlock TF2John\\n       False       True   \n",
       "2                               updated changelog\\n        True       True   \n",
       "3                                         Cleanup\\n       False       True   \n",
       "4                      [maint] Updating copyright\\n        True       True   \n",
       "\n",
       "   capital_first_token  not_period_end  imperative_mood  good_message  \n",
       "0                 True            True            False         False  \n",
       "1                 True            True             True         False  \n",
       "2                False            True             True         False  \n",
       "3                 True            True            False         False  \n",
       "4                False            True             True         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = pd.read_parquet(tagged_trainset_path)\n",
    "dev_set = pd.read_parquet(tagged_devset_path)\n",
    "test_set = pd.read_parquet(tagged_testset_path)\n",
    "print(train_set.shape, dev_set.shape, test_set.shape)\n",
    "display(train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562500, 2) (562500, 3) (562500,)\n"
     ]
    }
   ],
   "source": [
    "train_set_text_features = train_set.loc[:, [\"subject\", \"first_segment_message\"]]\n",
    "train_set_nontext_features = train_set.loc[:, [\"length_ok\", \"capital_first_token\", \"not_period_end\"]]\n",
    "train_set_labels = train_set.loc[:, \"good_message\"]\n",
    "print(train_set_text_features.shape, train_set_nontext_features.shape, train_set_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Learn to fit on feature col <subject> ... \n",
      "Tokenizer Learn to fit on feature col <first_segment_message> ... \n",
      "Tokenizer contains 243430 unique tokens...\n",
      "[0]: <Token: timeline> --> <ID: 280>\n",
      "[1]: <Token: update> --> <ID: 110756>\n",
      "[2]: <Token: extract> --> <ID: 1075>\n",
      "[3]: <Token: parameter> --> <ID: 2622>\n",
      "[4]: <Token: on> --> <ID: 36728>\n",
      "Tokenizer Started to Convert Text Features to Sequences ...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=100000, lower=True, oov_token=\"<unk>\")\n",
    "\n",
    "for col in train_set_text_features.columns:\n",
    "    print(f\"Tokenizer Learn to fit on feature col <{col}> ... \")\n",
    "    focus_texts = train_set_text_features[col]\n",
    "    tokenizer.fit_on_texts(focus_texts)\n",
    "\n",
    "print(f\"Tokenizer contains {tokenizer.word_counts.items().__len__()} unique tokens...\")\n",
    "_ = [print(f\"[{idx}]: <Token: {kv[0]}> --> <ID: {kv[1]}>\") for idx, kv in enumerate(tokenizer.word_counts.items()) if idx < 5]\n",
    "\n",
    "print(\"Tokenizer Started to Convert Text Features to Sequences ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Feature Engineering (Transform Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Working on train set\n",
      "(562500, 2) (562500, 3) (562500,)\n",
      "Transforming the text features <subject> ... \n",
      "Transforming the text features <first_segment_message> ... \n",
      "[0]: <Key: subject> --> <Shape of Attributes: (562500, 200)>\n",
      "[1]: <Key: first_segment_message> --> <Shape of Attributes: (562500, 200)>\n",
      "[2]: <Key: nontext_features> --> <Shape of Attributes: (562500, 3)>\n",
      "(562500, 403) (562500, 1) (562500, 404)\n"
     ]
    }
   ],
   "source": [
    "TEXT_FEATURE_COLUMNS = [\"subject\", \"first_segment_message\"]\n",
    "NONTEXT_FEATURE_COLUMNS = [\"length_ok\", \"capital_first_token\", \"not_period_end\"]\n",
    "LABEL_COLUMNS = \"good_message\"\n",
    "PRESET_TOKENIZER = tokenizer\n",
    "MAX_LEN = 200\n",
    "\n",
    "for focus_set_tag, focus_set in zip([\"train\", \"dev\", \"test\"], [train_set, dev_set, test_set]):\n",
    "    print(f\"\\n>>> Working on {focus_set_tag} set\")\n",
    "    \n",
    "    focus_set_text_features = focus_set.loc[:, TEXT_FEATURE_COLUMNS]\n",
    "    focus_set_nontext_features = focus_set.loc[:, NONTEXT_FEATURE_COLUMNS]\n",
    "    focus_set_labels = focus_set.loc[:, LABEL_COLUMNS]\n",
    "    print(focus_set_text_features.shape, focus_set_nontext_features.shape, focus_set_labels.shape)\n",
    "\n",
    "    \n",
    "    TRANSFORMED_FEATURES_DICT = {\"subject\": None, \"first_segment_message\": None, \"nontext_features\": None}\n",
    "\n",
    "    for col in focus_set_text_features.columns:\n",
    "        print(f\"Transforming the text features <{col}> ... \")\n",
    "        focus_texts = focus_set_text_features[col]\n",
    "        TRANSFORMED_FEATURES_DICT[col] = pad_sequences(tokenizer.texts_to_sequences(focus_texts), maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    focus_set_nontext_features = focus_set_nontext_features.astype(\"int32\").values\n",
    "    TRANSFORMED_FEATURES_DICT[\"nontext_features\"] = focus_set_nontext_features\n",
    "\n",
    "    _ = [print(f\"[{idx}]: <Key: {kv[0]}> --> <Shape of Attributes: {kv[1].shape}>\") for idx, kv in enumerate(TRANSFORMED_FEATURES_DICT.items()) if idx < 5]\n",
    "    \n",
    "    CONCATENATED_FEATURES = np.hstack([v for v in TRANSFORMED_FEATURES_DICT.values()])\n",
    "    CONCATENATED_LABELS = focus_set_labels.astype(\"int32\").values.reshape(-1, 1)\n",
    "    CONCATENATED_DATASET = pd.DataFrame(np.hstack([CONCATENATED_LABELS, CONCATENATED_FEATURES]))\n",
    "    print(CONCATENATED_FEATURES.shape, CONCATENATED_LABELS.shape, CONCATENATED_DATASET.shape)\n",
    "    CONCATENATED_DATASET.to_csv(f\"data/encoded/encoded_{focus_set_tag}_set.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localized Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Lambda, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleNet(input_dim=403, embedding_vocab_size=100000, embedding_dim=32, sequence_size=200):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "    text_x = Lambda(lambda x: x[:, : sequence_size * 2])(input_layer)\n",
    "    rule_x = Lambda(lambda x: x[:, sequence_size * 2 - input_dim :])(input_layer)\n",
    "\n",
    "    text_emb = Embedding(embedding_vocab_size, embedding_dim)(text_x)\n",
    "\n",
    "    text_pool = GlobalMaxPooling1D()(text_emb)\n",
    "\n",
    "    concat_x = Concatenate()([text_pool, rule_x])\n",
    "\n",
    "    x = Dense(32, activation='relu')(concat_x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training Data Will be Acquired From: ./data/encoded/encoded_train_set.csv\n",
      "... Validation Data Will be Acquired From: ./data/encoded/encoded_dev_set.csv\n",
      "Successfully Load Data, Shape of the features: (562500, 403)\n",
      "Successfully Load Data, Shape of the features: (187500, 403)\n",
      "[[2361    5    0 ...    1    1    1]\n",
      " [ 870  368   21 ...    1    1    1]\n",
      " [  29  187    0 ...    1    0    1]\n",
      " [ 109    0    0 ...    1    1    1]\n",
      " [2141  124  884 ...    1    0    1]]\n",
      "[0 0 0 0 0]\n",
      "[[   3   15   14 ...    1    1    1]\n",
      " [   7  186  743 ...    1    0    1]\n",
      " [ 445  338  276 ...    1    1    1]\n",
      " [   5  676    0 ...    1    1    1]\n",
      " [ 261    2 4321 ...    1    0    1]]\n"
     ]
    }
   ],
   "source": [
    "def acquire_inputs(input_data_dict):\n",
    "    \"\"\"\n",
    "    acquire the training set feature, label and validation set feature, label\n",
    "    wrap them into the proper manner that fit into the model training procedure\n",
    "    \"\"\"\n",
    "    \n",
    "    train_data_path = os.path.join(input_data_dict['train'], \"encoded_train_set.csv\")\n",
    "    validation_data_path = os.path.join(input_data_dict['validation'], \"encoded_dev_set.csv\")\n",
    "    print(\"... Training Data Will be Acquired From: {}\".format(train_data_path))\n",
    "    print(\"... Validation Data Will be Acquired From: {}\".format(validation_data_path))\n",
    "    encoded_trainset = pd.read_csv(train_data_path, header=None)\n",
    "    encoded_devset = pd.read_csv(validation_data_path, header=None)\n",
    "\n",
    "    encoded_trainset_feature = encoded_trainset.iloc[:, 1:].values\n",
    "    encoded_trainset_label = encoded_trainset.iloc[:, 0].values\n",
    "    encoded_trainset = None\n",
    "    print(\"Successfully Load Data, Shape of the features:\", encoded_trainset_feature.shape)\n",
    "\n",
    "    encoded_devset_feature = encoded_devset.iloc[:, 1:].values\n",
    "    encoded_devset_label = encoded_devset.iloc[:, 0].values\n",
    "    encoded_devset = None\n",
    "    print(\"Successfully Load Data, Shape of the features:\", encoded_devset_feature.shape)\n",
    "    return encoded_trainset_feature, encoded_trainset_label, (encoded_devset_feature, encoded_devset_label)\n",
    "\n",
    "encoded_data_dir = \"./data/encoded\"\n",
    "channel_input_dirs = {\"train\": encoded_data_dir, \"validation\": encoded_data_dir, \"test\": encoded_data_dir}\n",
    "x_train, y_train, validation_data = acquire_inputs(channel_input_dirs)\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])\n",
    "print(validation_data[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 403)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 400)          0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 400, 32)      3200000     lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 32)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 3)            0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 35)           0           global_max_pooling1d_11[0][0]    \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           1152        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            33          dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,201,185\n",
      "Trainable params: 3,201,185\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model will be saved to ./model.hdf5 ...\n",
      "Train on 562500 samples, validate on 187500 samples\n",
      "Epoch 1/3\n",
      "562432/562500 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9559\n",
      "Epoch 00001: val_loss improved from inf to 0.06501, saving model to ./model.hdf5\n",
      "562500/562500 [==============================] - 68s 121us/sample - loss: 0.1213 - acc: 0.9559 - val_loss: 0.0650 - val_acc: 0.9725\n",
      "Epoch 2/3\n",
      "562176/562500 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9765\n",
      "Epoch 00002: val_loss improved from 0.06501 to 0.06175, saving model to ./model.hdf5\n",
      "562500/562500 [==============================] - 68s 121us/sample - loss: 0.0572 - acc: 0.9765 - val_loss: 0.0618 - val_acc: 0.9735\n",
      "Epoch 3/3\n",
      "562432/562500 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9808\n",
      "Epoch 00003: val_loss did not improve from 0.06175\n",
      "562500/562500 [==============================] - 67s 120us/sample - loss: 0.0476 - acc: 0.9808 - val_loss: 0.0625 - val_acc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "# Provided train function\n",
    "def train(model, train_data_feature, train_data_label, validation_data, epochs=10, model_dir=None, verbose=1, batch_size=128):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the tensorflow training script\n",
    "    \"\"\"\n",
    "    model.summary()\n",
    "    \n",
    "    model_path = os.path.join(model_dir, \"model.hdf5\")\n",
    "    print(f\"Model will be saved to {model_path} ...\")\n",
    "    \n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_path, monitor='val_loss', verbose=1, save_best_only=True, \n",
    "        mode='auto', save_freq='epoch', options=None\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        x=train_data_feature, y=train_data_label, \n",
    "        validation_data=validation_data,\n",
    "        epochs=epochs, verbose=verbose,\n",
    "        shuffle=True, batch_size=batch_size,\n",
    "        callbacks = [ckpt]\n",
    "    )\n",
    "        \n",
    "EMBEDDING_DIM = 32\n",
    "EMBEDDING_VOCAB_SIZE = 100000\n",
    "TOTAL_FEATURE_DIM = 403\n",
    "SEQUENCE_SIZE = 200\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 3\n",
    "\n",
    "model = SimpleNet(input_dim = TOTAL_FEATURE_DIM, \n",
    "                  embedding_vocab_size = EMBEDDING_VOCAB_SIZE,\n",
    "                  embedding_dim = EMBEDDING_DIM,\n",
    "                  sequence_size = SEQUENCE_SIZE)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "model_dir = \"./\"\n",
    "train(model, x_train, y_train, validation_data, epochs=3, model_dir=model_dir, verbose=1, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 403)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 400)          0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 400, 32)      3200000     lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 32)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 3)            0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 35)           0           global_max_pooling1d_11[0][0]    \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           1152        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            33          dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,201,185\n",
      "Trainable params: 3,201,185\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model.hdf5\"\n",
    "model_reload = tf.keras.models.load_model(model_path)\n",
    "model_reload.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset: ./data/encoded/encoded_train_set.csv\n",
      "Devset: ./data/encoded/encoded_dev_set.csv\n",
      "Testset: ./data/encoded/encoded_test_set.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/encoded\"\n",
    "encoded_trainset_path = os.path.join(data_dir, \"encoded_train_set.csv\")\n",
    "encoded_devset_path = os.path.join(data_dir, \"encoded_dev_set.csv\")\n",
    "encoded_testset_path = os.path.join(data_dir, \"encoded_test_set.csv\")\n",
    "print(\"Trainset:\", encoded_trainset_path)\n",
    "print(\"Devset:\", encoded_devset_path)\n",
    "print(\"Testset:\", encoded_testset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using role: arn:aws:iam::259046265119:role/service-role/AmazonSageMaker-ExecutionRole-20200813T153989\n",
      "Using bucket: sagemaker-us-east-1-259046265119\n"
     ]
    }
   ],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"Using role: {role}\")\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Using bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]: ./data/encoded/encoded_train_set.csv --> s3://sagemaker-us-east-1-259046265119/commit_msg_data/train/encoded_train_set.csv\n",
      "[validation]: ./data/encoded/encoded_dev_set.csv --> s3://sagemaker-us-east-1-259046265119/commit_msg_data/validation/encoded_dev_set.csv\n",
      "[test]: ./data/encoded/encoded_test_set.csv --> s3://sagemaker-us-east-1-259046265119/commit_msg_data/test/encoded_test_set.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 's3://sagemaker-us-east-1-259046265119/commit_msg_data/train/encoded_train_set.csv',\n",
       " 'validation': 's3://sagemaker-us-east-1-259046265119/commit_msg_data/validation/encoded_dev_set.csv',\n",
       " 'test': 's3://sagemaker-us-east-1-259046265119/commit_msg_data/test/encoded_test_set.csv'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload to S3\n",
    "tags = [\"train\", \"validation\", \"test\"]\n",
    "upload_paths = [encoded_trainset_path, encoded_devset_path, encoded_testset_path]\n",
    "input_data = {}\n",
    "\n",
    "for tag, upload_path in zip(tags, upload_paths):\n",
    "    prefix = f'commit_msg_data/{tag}'\n",
    "    input_data[tag] = sagemaker_session.upload_data(path=upload_path, bucket=bucket, key_prefix=prefix)\n",
    "    print(f\"[{tag}]: {upload_path} --> {input_data[tag]}\")\n",
    "\n",
    "print('')\n",
    "display(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit_msg_data/test/encoded_test_set.csv\n",
      "commit_msg_data/train/encoded_train_set.csv\n",
      "commit_msg_data/validation/encoded_dev_set.csv\n"
     ]
    }
   ],
   "source": [
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    if any([identifier in obj.key for identifier in [\"csv\"]]):\n",
    "         print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling: Create Tensorflow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact will be output to: s3://sagemaker-us-east-1-259046265119/commit_msg_model\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# specify an output path\n",
    "# prefix is specified above\n",
    "\n",
    "output_prefix=\"commit_msg_model\"\n",
    "output_path = 's3://{}/{}'.format(bucket, output_prefix)\n",
    "print(f\"Model artifact will be output to: {output_path}\")\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='codes', # this should be just \"source\" for your code\n",
    "                       role=role,\n",
    "                       framework_version='2.1',\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.m5.xlarge',\n",
    "                       output_path=output_path,\n",
    "                       model_dir=False,\n",
    "                       sagemaker_session=sagemaker_session,\n",
    "                       py_version=\"py3\",\n",
    "                       hyperparameters={\n",
    "                           'epochs': 5, # could change to higher\n",
    "                           'batch_size': 128\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': '5', 'batch_size': '128'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-28 02:08:52 Starting - Starting the training job...\n",
      "2020-11-28 02:08:54 Starting - Launching requested ML instances......\n",
      "2020-11-28 02:10:07 Starting - Preparing the instances for training...\n",
      "2020-11-28 02:10:42 Downloading - Downloading input data......\n",
      "2020-11-28 02:11:52 Training - Downloading the training image...\n",
      "2020-11-28 02:12:07 Training - Training image download completed. Training in progress.\u001b[34m2020-11-28 02:12:11,318 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-11-28 02:12:11,325 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-28 02:12:18,900 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-28 02:12:18,915 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-28 02:12:18,929 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-28 02:12:18,938 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2020-11-28-02-08-51-966\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-259046265119/tensorflow-training-2020-11-28-02-08-51-966/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":128,\"epochs\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-259046265119/tensorflow-training-2020-11-28-02-08-51-966/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-11-28-02-08-51-966\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-259046265119/tensorflow-training-2020-11-28-02-08-51-966/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --batch_size 128 --epochs 5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m============== Parsed Args ===============: \u001b[0m\n",
      "\u001b[34mNamespace(batch_size=128, current_host='algo-1', data_dir='/opt/ml/input/data/train', embedding_dim=32, embedding_vocab_size=100000, epochs=5, hosts=['algo-1'], model_dir='/opt/ml/model', sequence_size=200, total_feature_dim=403, train_env={'additional_framework_parameters': {}, 'channel_input_dirs': {'test': '/opt/ml/input/data/test', 'train': '/opt/ml/input/data/train', 'validation': '/opt/ml/input/data/validation'}, 'current_host': 'algo-1', 'framework_module': 'sagemaker_tensorflow_container.training:main', 'hosts': ['algo-1'], 'hyperparameters': {'batch_size': 128, 'epochs': 5}, 'input_config_dir': '/opt/ml/input/config', 'input_data_config': {'test': {'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated', 'TrainingInputMode': 'File'}, 'train': {'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated', 'TrainingInputMode': 'File'}, 'validation': {'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated', 'TrainingInputMode': 'File'}}, 'input_dir': '/opt/ml/input', 'is_master': True, 'job_name': 'tensorflow-training-2020-11-28-02-08-51-966', 'log_level': 20, 'master_hostname': 'algo-1', 'model_dir': '/opt/ml/model', 'module_dir': 's3://sagemaker-us-east-1-259046265119/tensorflow-training-2020-11-28-02-08-51-966/source/sourcedir.tar.gz', 'module_name': 'train', 'network_interface_name': 'eth0', 'num_cpus': 4, 'num_gpus': 0, 'output_data_dir': '/opt/ml/output/data', 'output_dir': '/opt/ml/output', 'output_intermediate_dir': '/opt/ml/output/intermediate', 'resource_config': {'current_host': 'algo-1', 'hosts': ['algo-1'], 'network_interface_name': 'eth0'}, 'user_entry_point': 'train.py'})\u001b[0m\n",
      "\u001b[34m[2020-11-28 02:12:20.918 ip-10-2-122-195.ec2.internal:25 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-11-28 02:12:20.918 ip-10-2-122-195.ec2.internal:25 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-11-28 02:12:20.918 ip-10-2-122-195.ec2.internal:25 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-11-28 02:12:20.918 ip-10-2-122-195.ec2.internal:25 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-11-28 02:12:20.949 ip-10-2-122-195.ec2.internal:25 INFO hook.py:398] Monitoring the collections: sm_metrics, metrics, losses\u001b[0m\n",
      "\u001b[34mModel: \"model\"\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                    Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34minput_1 (InputLayer)            [(None, 403)]        0                                            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mlambda (Lambda)                 (None, 400)          0           input_1[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membedding (Embedding)           (None, 400, 32)      3200000     lambda[0][0]                     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mglobal_max_pooling1d (GlobalMax (None, 32)           0           embedding[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mlambda_1 (Lambda)               (None, 3)            0           input_1[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate (Concatenate)       (None, 35)           0           global_max_pooling1d[0][0]       \n",
      "                                                                 lambda_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense (Dense)                   (None, 32)           1152        concatenate[0][0]                \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 3,201,185\u001b[0m\n",
      "\u001b[34mTrainable params: 3,201,185\u001b[0m\n",
      "\u001b[34mNon-trainable params: 0\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m... Training Data Will be Acquired From: /opt/ml/input/data/train/encoded_train_set.csv\u001b[0m\n",
      "\u001b[34m... Validation Data Will be Acquired From: /opt/ml/input/data/validation/encoded_dev_set.csv\u001b[0m\n",
      "\u001b[34mSuccessfully Load Data, Shape of the features: (562500, 403)\u001b[0m\n",
      "\u001b[34mSuccessfully Load Data, Shape of the features: (187500, 403)\u001b[0m\n",
      "\u001b[34mModel saved to /opt/ml/model/tensorflow_model/1\u001b[0m\n",
      "\u001b[34mTrain on 562500 samples, validate on 187500 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m562500/562500 - 125s - loss: 0.1276 - acc: 0.9512 - val_loss: 0.0821 - val_acc: 0.9684\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m562500/562500 - 124s - loss: 0.0778 - acc: 0.9693 - val_loss: 0.0801 - val_acc: 0.9689\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m562500/562500 - 122s - loss: 0.0733 - acc: 0.9705 - val_loss: 0.0812 - val_acc: 0.9684\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m562500/562500 - 123s - loss: 0.0703 - acc: 0.9716 - val_loss: 0.0826 - val_acc: 0.9682\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\n",
      "2020-11-28 02:23:00 Uploading - Uploading generated training model\u001b[34m562500/562500 - 122s - loss: 0.0682 - acc: 0.9721 - val_loss: 0.0837 - val_acc: 0.9672\u001b[0m\n",
      "\u001b[34m2020-11-28 02:22:56,276 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-28 02:23:07 Completed - Training job completed\n",
      "Training seconds: 745\n",
      "Billable seconds: 745\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs = input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model Artifact from s3://sagemaker-us-east-1-259046265119/commit_msg_model/tensorflow-training-2020-11-28-02-08-51-966/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = TensorFlowModel(model_data=estimator.model_data,\n",
    "                   role = role,\n",
    "                   framework_version='2.1',\n",
    "                   entry_point='predict.py',\n",
    "                   source_dir='codes')\n",
    "\n",
    "print(f\"Using Model Artifact from {estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!CPU times: user 3.89 s, sys: 124 ms, total: 4.01 s\n",
      "Wall time: 8min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset: ./data/encoded/encoded_train_set.csv\n",
      "Devset: ./data/encoded/encoded_dev_set.csv\n",
      "Testset: ./data/encoded/encoded_test_set.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/encoded\"\n",
    "encoded_trainset_path = os.path.join(data_dir, \"encoded_train_set.csv\")\n",
    "encoded_devset_path = os.path.join(data_dir, \"encoded_dev_set.csv\")\n",
    "encoded_testset_path = os.path.join(data_dir, \"encoded_test_set.csv\")\n",
    "print(\"Trainset:\", encoded_trainset_path)\n",
    "print(\"Devset:\", encoded_devset_path)\n",
    "print(\"Testset:\", encoded_testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictor, test_features, test_labels, verbose=True, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # rounding and squeezing array\n",
    "    test_preds = []\n",
    "    print(\"Start Fetching Predictor Response ...\")\n",
    "    for batch_idx in range(int(np.ceil(len(test_labels) / batch_size))):\n",
    "        min_sample_idx = batch_idx * batch_size\n",
    "        max_sample_idx = (batch_idx + 1) * batch_size\n",
    "#         print(batch_idx, (min_sample_idx, max_sample_idx))\n",
    "        focus_test_preds = np.squeeze(np.round(predictor.predict(test_features[min_sample_idx:max_sample_idx])[\"predictions\"]))\n",
    "        test_preds.append(focus_test_preds)\n",
    "        print(f\"Finished Predict Sample ({min_sample_idx} ~ {max_sample_idx})\")\n",
    "    test_preds = np.array(test_preds).flatten()\n",
    "    print(f\"Acquired All Prediction Results, Total Shape {test_preds.shape}\")\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 403) (250000,)\n"
     ]
    }
   ],
   "source": [
    "encoded_testset = pd.read_csv(encoded_testset_path, header=None)\n",
    "encoded_testset_feature = encoded_testset.iloc[:, 1:].values\n",
    "encoded_testset_label = encoded_testset.iloc[:, 0].values\n",
    "print(encoded_testset_feature.shape, encoded_testset_label.shape)\n",
    "\n",
    "test_features = encoded_testset_feature\n",
    "test_labels = encoded_testset_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "## Test on the evaluation func\n",
    "print(np.squeeze(np.round(predictor.predict(encoded_testset_feature[:20])[\"predictions\"])))\n",
    "print(encoded_testset_label[:20].astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fetching Predictor Response ...\n",
      "Finished Predict Sample (0 ~ 10000)\n",
      "Finished Predict Sample (10000 ~ 20000)\n",
      "Finished Predict Sample (20000 ~ 30000)\n",
      "Finished Predict Sample (30000 ~ 40000)\n",
      "Finished Predict Sample (40000 ~ 50000)\n",
      "Finished Predict Sample (50000 ~ 60000)\n",
      "Finished Predict Sample (60000 ~ 70000)\n",
      "Finished Predict Sample (70000 ~ 80000)\n",
      "Finished Predict Sample (80000 ~ 90000)\n",
      "Finished Predict Sample (90000 ~ 100000)\n",
      "Finished Predict Sample (100000 ~ 110000)\n",
      "Finished Predict Sample (110000 ~ 120000)\n",
      "Finished Predict Sample (120000 ~ 130000)\n",
      "Finished Predict Sample (130000 ~ 140000)\n",
      "Finished Predict Sample (140000 ~ 150000)\n",
      "Finished Predict Sample (150000 ~ 160000)\n",
      "Finished Predict Sample (160000 ~ 170000)\n",
      "Finished Predict Sample (170000 ~ 180000)\n",
      "Finished Predict Sample (180000 ~ 190000)\n",
      "Finished Predict Sample (190000 ~ 200000)\n",
      "Finished Predict Sample (200000 ~ 210000)\n",
      "Finished Predict Sample (210000 ~ 220000)\n",
      "Finished Predict Sample (220000 ~ 230000)\n",
      "Finished Predict Sample (230000 ~ 240000)\n",
      "Finished Predict Sample (240000 ~ 250000)\n",
      "Acquired All Prediction Results, Total Shape (250000,)\n",
      "predictions     0.0    1.0\n",
      "actuals                   \n",
      "0            211578   4586\n",
      "1              3831  30005\n",
      "\n",
      "Recall:     0.887\n",
      "Precision:  0.867\n",
      "Accuracy:   0.966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_resp, test_preds = evaluate(predictor, encoded_testset_feature, encoded_testset_label, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Meta Prediction Result and EDA on the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>first_segment_message</th>\n",
       "      <th>identifier</th>\n",
       "      <th>length_ok</th>\n",
       "      <th>capital_first_token</th>\n",
       "      <th>not_period_end</th>\n",
       "      <th>imperative_mood</th>\n",
       "      <th>good_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Williams</td>\n",
       "      <td>1266961419</td>\n",
       "      <td>Improve spec coverage of DSL::ValidationBuilder.</td>\n",
       "      <td>Improve spec coverage of DSL::ValidationBuilde...</td>\n",
       "      <td>Improve spec coverage of DSL::ValidationBuilder.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emiliano Viada</td>\n",
       "      <td>1394075171</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>Initial commit\\n</td>\n",
       "      <td>Initial commit\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olaf Hering</td>\n",
       "      <td>1084201652</td>\n",
       "      <td>+- add patches.arch/suse-ppc64-export-HvLpEven...</td>\n",
       "      <td>+- add patches.arch/suse-ppc64-export-HvLpEven...</td>\n",
       "      <td>+- add patches.arch/suse-ppc64-export-HvLpEven...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Franck Dakia</td>\n",
       "      <td>1452790141</td>\n",
       "      <td>suppression de composer.lock et ajout du fichi...</td>\n",
       "      <td>suppression de composer.lock et ajout du fichi...</td>\n",
       "      <td>suppression de composer.lock et ajout du fichi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SpootDev</td>\n",
       "      <td>1477624193</td>\n",
       "      <td>rename</td>\n",
       "      <td>rename\\n</td>\n",
       "      <td>rename\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name    time_sec  \\\n",
       "0  Anthony Williams  1266961419   \n",
       "1    Emiliano Viada  1394075171   \n",
       "2       Olaf Hering  1084201652   \n",
       "3      Franck Dakia  1452790141   \n",
       "4          SpootDev  1477624193   \n",
       "\n",
       "                                             subject  \\\n",
       "0   Improve spec coverage of DSL::ValidationBuilder.   \n",
       "1                                     Initial commit   \n",
       "2  +- add patches.arch/suse-ppc64-export-HvLpEven...   \n",
       "3  suppression de composer.lock et ajout du fichi...   \n",
       "4                                             rename   \n",
       "\n",
       "                                             message  \\\n",
       "0  Improve spec coverage of DSL::ValidationBuilde...   \n",
       "1                                   Initial commit\\n   \n",
       "2  +- add patches.arch/suse-ppc64-export-HvLpEven...   \n",
       "3  suppression de composer.lock et ajout du fichi...   \n",
       "4                                           rename\\n   \n",
       "\n",
       "                               first_segment_message  identifier  length_ok  \\\n",
       "0   Improve spec coverage of DSL::ValidationBuilder.       False       True   \n",
       "1                                   Initial commit\\n       False       True   \n",
       "2  +- add patches.arch/suse-ppc64-export-HvLpEven...        True      False   \n",
       "3  suppression de composer.lock et ajout du fichi...       False      False   \n",
       "4                                           rename\\n        True       True   \n",
       "\n",
       "   capital_first_token  not_period_end  imperative_mood  good_message  \n",
       "0                 True           False             True         False  \n",
       "1                 True            True            False         False  \n",
       "2                False            True             True         False  \n",
       "3                False            True            False         False  \n",
       "4                False            True            False         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \"./data/\"\n",
    "tagged_testset_path = os.path.join(data_dir, \"labeled_commit_message_test.parquet\")\n",
    "tagged_testset = pd.read_parquet(tagged_testset_path)\n",
    "display(tagged_testset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>first_segment_message</th>\n",
       "      <th>identifier</th>\n",
       "      <th>length_ok</th>\n",
       "      <th>capital_first_token</th>\n",
       "      <th>not_period_end</th>\n",
       "      <th>imperative_mood</th>\n",
       "      <th>good_message</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Williams</td>\n",
       "      <td>1266961419</td>\n",
       "      <td>Improve spec coverage of DSL::ValidationBuilder.</td>\n",
       "      <td>Improve spec coverage of DSL::ValidationBuilde...</td>\n",
       "      <td>Improve spec coverage of DSL::ValidationBuilder.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emiliano Viada</td>\n",
       "      <td>1394075171</td>\n",
       "      <td>Initial commit</td>\n",
       "      <td>Initial commit\\n</td>\n",
       "      <td>Initial commit\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olaf Hering</td>\n",
       "      <td>1084201652</td>\n",
       "      <td>+- add patches.arch/suse-ppc64-export-HvLpEven...</td>\n",
       "      <td>+- add patches.arch/suse-ppc64-export-HvLpEven...</td>\n",
       "      <td>+- add patches.arch/suse-ppc64-export-HvLpEven...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Franck Dakia</td>\n",
       "      <td>1452790141</td>\n",
       "      <td>suppression de composer.lock et ajout du fichi...</td>\n",
       "      <td>suppression de composer.lock et ajout du fichi...</td>\n",
       "      <td>suppression de composer.lock et ajout du fichi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SpootDev</td>\n",
       "      <td>1477624193</td>\n",
       "      <td>rename</td>\n",
       "      <td>rename\\n</td>\n",
       "      <td>rename\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name    time_sec  \\\n",
       "0  Anthony Williams  1266961419   \n",
       "1    Emiliano Viada  1394075171   \n",
       "2       Olaf Hering  1084201652   \n",
       "3      Franck Dakia  1452790141   \n",
       "4          SpootDev  1477624193   \n",
       "\n",
       "                                             subject  \\\n",
       "0   Improve spec coverage of DSL::ValidationBuilder.   \n",
       "1                                     Initial commit   \n",
       "2  +- add patches.arch/suse-ppc64-export-HvLpEven...   \n",
       "3  suppression de composer.lock et ajout du fichi...   \n",
       "4                                             rename   \n",
       "\n",
       "                                             message  \\\n",
       "0  Improve spec coverage of DSL::ValidationBuilde...   \n",
       "1                                   Initial commit\\n   \n",
       "2  +- add patches.arch/suse-ppc64-export-HvLpEven...   \n",
       "3  suppression de composer.lock et ajout du fichi...   \n",
       "4                                           rename\\n   \n",
       "\n",
       "                               first_segment_message  identifier  length_ok  \\\n",
       "0   Improve spec coverage of DSL::ValidationBuilder.       False       True   \n",
       "1                                   Initial commit\\n       False       True   \n",
       "2  +- add patches.arch/suse-ppc64-export-HvLpEven...        True      False   \n",
       "3  suppression de composer.lock et ajout du fichi...       False      False   \n",
       "4                                           rename\\n        True       True   \n",
       "\n",
       "   capital_first_token  not_period_end  imperative_mood  good_message  \\\n",
       "0                 True           False             True         False   \n",
       "1                 True            True            False         False   \n",
       "2                False            True             True         False   \n",
       "3                False            True            False         False   \n",
       "4                False            True            False         False   \n",
       "\n",
       "   prediction  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagged_testset_with_pred = tagged_testset.copy()\n",
    "tagged_testset_with_pred[\"prediction\"] = test_preds\n",
    "tagged_testset_with_pred[\"prediction\"] = tagged_testset_with_pred[\"prediction\"].astype(bool)\n",
    "display(tagged_testset_with_pred.head())\n",
    "\n",
    "tagged_testset_with_pred.to_parquet(os.path.join(data_dir, \"labeled_commit_message_test_with_pred.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4586, 12) (3831, 12)\n"
     ]
    }
   ],
   "source": [
    "FP_samples = tagged_testset_with_pred.loc[(tagged_testset_with_pred[\"good_message\"] == False) & (tagged_testset_with_pred[\"prediction\"] == True)]\n",
    "FN_samples = tagged_testset_with_pred.loc[(tagged_testset_with_pred[\"good_message\"] == True) & (tagged_testset_with_pred[\"prediction\"] == False)]\n",
    "print(FP_samples.shape, FN_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>first_segment_message</th>\n",
       "      <th>identifier</th>\n",
       "      <th>length_ok</th>\n",
       "      <th>capital_first_token</th>\n",
       "      <th>not_period_end</th>\n",
       "      <th>imperative_mood</th>\n",
       "      <th>good_message</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Neil Marchant</td>\n",
       "      <td>1478477978</td>\n",
       "      <td>Removed ElasticNet (not CV)</td>\n",
       "      <td>Removed ElasticNet (not CV)\\n</td>\n",
       "      <td>Removed ElasticNet (not CV)\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Michal Čihař</td>\n",
       "      <td>1456743084</td>\n",
       "      <td>Fix tests after #12032</td>\n",
       "      <td>Fix tests after #12032\\n\\nSigned-off-by: Micha...</td>\n",
       "      <td>Fix tests after #12032</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>1492280619</td>\n",
       "      <td>Updated Readme</td>\n",
       "      <td>Updated Readme\\n\\nAdded example descriptions.</td>\n",
       "      <td>Updated Readme</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>1468547776</td>\n",
       "      <td>Fix links</td>\n",
       "      <td>Fix links</td>\n",
       "      <td>Fix links</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Lorenzo Tomasini</td>\n",
       "      <td>1479902588</td>\n",
       "      <td>Fix: bug in vim choice</td>\n",
       "      <td>Fix: bug in vim choice\\n</td>\n",
       "      <td>Fix: bug in vim choice\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Teddy Zhang</td>\n",
       "      <td>1533614883</td>\n",
       "      <td>Fix code style</td>\n",
       "      <td>Fix code style\\n</td>\n",
       "      <td>Fix code style\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>erwinwinder</td>\n",
       "      <td>1426003834</td>\n",
       "      <td>Fix for github issue #2617</td>\n",
       "      <td>Fix for github issue #2617\\n</td>\n",
       "      <td>Fix for github issue #2617\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>willmcgugan@gmail.com</td>\n",
       "      <td>1363526970</td>\n",
       "      <td>Tests for mountfile</td>\n",
       "      <td>Tests for mountfile\\n\\ngit-svn-id: 74b2def6592...</td>\n",
       "      <td>Tests for mountfile</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Ian Dunn</td>\n",
       "      <td>1415818504</td>\n",
       "      <td>Add Sq tests</td>\n",
       "      <td>Add Sq tests\\n</td>\n",
       "      <td>Add Sq tests\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Ciaran Gultnieks</td>\n",
       "      <td>1398947753</td>\n",
       "      <td>Update Easy Dice to 1.6 (4)</td>\n",
       "      <td>Update Easy Dice to 1.6 (4)\\n</td>\n",
       "      <td>Update Easy Dice to 1.6 (4)\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Anne Jan Brouwer</td>\n",
       "      <td>1498662247</td>\n",
       "      <td>Merge github.com:micropython/micropython</td>\n",
       "      <td>Merge github.com:micropython/micropython\\n</td>\n",
       "      <td>Merge github.com:micropython/micropython\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Shea Bunge</td>\n",
       "      <td>1542882354</td>\n",
       "      <td>Fix name to tag-it stylesheet</td>\n",
       "      <td>Fix name to tag-it stylesheet\\n</td>\n",
       "      <td>Fix name to tag-it stylesheet\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Svyatoslav ILINSKIY</td>\n",
       "      <td>1438931591</td>\n",
       "      <td>Fix Windows size bug</td>\n",
       "      <td>Fix Windows size bug\\n</td>\n",
       "      <td>Fix Windows size bug\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Pelle Wessman</td>\n",
       "      <td>1247047486</td>\n",
       "      <td>Added Transliteration 6.x-2.1</td>\n",
       "      <td>Added Transliteration 6.x-2.1</td>\n",
       "      <td>Added Transliteration 6.x-2.1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>gcdev373</td>\n",
       "      <td>1587656973</td>\n",
       "      <td>Fix Import/Export serialisation tests</td>\n",
       "      <td>Fix Import/Export serialisation tests\\n</td>\n",
       "      <td>Fix Import/Export serialisation tests\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Andrew Huynh</td>\n",
       "      <td>1364580585</td>\n",
       "      <td>Merged DHLab layout onto heat map viz</td>\n",
       "      <td>Merged DHLab layout onto heat map viz</td>\n",
       "      <td>Merged DHLab layout onto heat map viz</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Igor Khomenko</td>\n",
       "      <td>1398433416</td>\n",
       "      <td>Updated SDK to 1.2</td>\n",
       "      <td>Updated SDK to 1.2</td>\n",
       "      <td>Updated SDK to 1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>1482408406</td>\n",
       "      <td>Grammar fix</td>\n",
       "      <td>Grammar fix</td>\n",
       "      <td>Grammar fix</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Wohlstand</td>\n",
       "      <td>1430639009</td>\n",
       "      <td>Fix of editor freezing after test</td>\n",
       "      <td>Fix of editor freezing after test\\n</td>\n",
       "      <td>Fix of editor freezing after test\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Ary Borenszweig</td>\n",
       "      <td>1273261799</td>\n",
       "      <td>Implemented /api/channels/:name.:format</td>\n",
       "      <td>Implemented /api/channels/:name.:format\\n\\n--H...</td>\n",
       "      <td>Implemented /api/channels/:name.:format</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name    time_sec  \\\n",
       "236          Neil Marchant  1478477978   \n",
       "253           Michal Čihař  1456743084   \n",
       "262                 GitHub  1492280619   \n",
       "289                 GitHub  1468547776   \n",
       "309       Lorenzo Tomasini  1479902588   \n",
       "339            Teddy Zhang  1533614883   \n",
       "361            erwinwinder  1426003834   \n",
       "379  willmcgugan@gmail.com  1363526970   \n",
       "438               Ian Dunn  1415818504   \n",
       "464       Ciaran Gultnieks  1398947753   \n",
       "550       Anne Jan Brouwer  1498662247   \n",
       "588             Shea Bunge  1542882354   \n",
       "747    Svyatoslav ILINSKIY  1438931591   \n",
       "763          Pelle Wessman  1247047486   \n",
       "778               gcdev373  1587656973   \n",
       "789           Andrew Huynh  1364580585   \n",
       "794          Igor Khomenko  1398433416   \n",
       "816                 GitHub  1482408406   \n",
       "843              Wohlstand  1430639009   \n",
       "855        Ary Borenszweig  1273261799   \n",
       "\n",
       "                                      subject  \\\n",
       "236               Removed ElasticNet (not CV)   \n",
       "253                    Fix tests after #12032   \n",
       "262                            Updated Readme   \n",
       "289                                 Fix links   \n",
       "309                    Fix: bug in vim choice   \n",
       "339                            Fix code style   \n",
       "361                Fix for github issue #2617   \n",
       "379                       Tests for mountfile   \n",
       "438                              Add Sq tests   \n",
       "464               Update Easy Dice to 1.6 (4)   \n",
       "550  Merge github.com:micropython/micropython   \n",
       "588             Fix name to tag-it stylesheet   \n",
       "747                      Fix Windows size bug   \n",
       "763             Added Transliteration 6.x-2.1   \n",
       "778     Fix Import/Export serialisation tests   \n",
       "789     Merged DHLab layout onto heat map viz   \n",
       "794                        Updated SDK to 1.2   \n",
       "816                               Grammar fix   \n",
       "843         Fix of editor freezing after test   \n",
       "855   Implemented /api/channels/:name.:format   \n",
       "\n",
       "                                               message  \\\n",
       "236                      Removed ElasticNet (not CV)\\n   \n",
       "253  Fix tests after #12032\\n\\nSigned-off-by: Micha...   \n",
       "262      Updated Readme\\n\\nAdded example descriptions.   \n",
       "289                                          Fix links   \n",
       "309                           Fix: bug in vim choice\\n   \n",
       "339                                   Fix code style\\n   \n",
       "361                       Fix for github issue #2617\\n   \n",
       "379  Tests for mountfile\\n\\ngit-svn-id: 74b2def6592...   \n",
       "438                                     Add Sq tests\\n   \n",
       "464                      Update Easy Dice to 1.6 (4)\\n   \n",
       "550         Merge github.com:micropython/micropython\\n   \n",
       "588                    Fix name to tag-it stylesheet\\n   \n",
       "747                             Fix Windows size bug\\n   \n",
       "763                      Added Transliteration 6.x-2.1   \n",
       "778            Fix Import/Export serialisation tests\\n   \n",
       "789              Merged DHLab layout onto heat map viz   \n",
       "794                                 Updated SDK to 1.2   \n",
       "816                                        Grammar fix   \n",
       "843                Fix of editor freezing after test\\n   \n",
       "855  Implemented /api/channels/:name.:format\\n\\n--H...   \n",
       "\n",
       "                          first_segment_message  identifier  length_ok  \\\n",
       "236               Removed ElasticNet (not CV)\\n       False       True   \n",
       "253                      Fix tests after #12032        True       True   \n",
       "262                              Updated Readme       False       True   \n",
       "289                                   Fix links        True       True   \n",
       "309                    Fix: bug in vim choice\\n        True       True   \n",
       "339                            Fix code style\\n        True       True   \n",
       "361                Fix for github issue #2617\\n        True       True   \n",
       "379                         Tests for mountfile        True       True   \n",
       "438                              Add Sq tests\\n        True       True   \n",
       "464               Update Easy Dice to 1.6 (4)\\n        True       True   \n",
       "550  Merge github.com:micropython/micropython\\n       False       True   \n",
       "588             Fix name to tag-it stylesheet\\n        True       True   \n",
       "747                      Fix Windows size bug\\n       False       True   \n",
       "763               Added Transliteration 6.x-2.1       False       True   \n",
       "778     Fix Import/Export serialisation tests\\n        True       True   \n",
       "789       Merged DHLab layout onto heat map viz       False       True   \n",
       "794                          Updated SDK to 1.2       False       True   \n",
       "816                                 Grammar fix        True       True   \n",
       "843         Fix of editor freezing after test\\n        True       True   \n",
       "855     Implemented /api/channels/:name.:format       False       True   \n",
       "\n",
       "     capital_first_token  not_period_end  imperative_mood  good_message  \\\n",
       "236                 True            True            False         False   \n",
       "253                 True            True            False         False   \n",
       "262                 True            True            False         False   \n",
       "289                 True            True            False         False   \n",
       "309                 True            True            False         False   \n",
       "339                 True            True            False         False   \n",
       "361                 True            True            False         False   \n",
       "379                 True            True            False         False   \n",
       "438                 True            True            False         False   \n",
       "464                 True            True            False         False   \n",
       "550                 True            True            False         False   \n",
       "588                 True            True            False         False   \n",
       "747                 True            True            False         False   \n",
       "763                 True            True            False         False   \n",
       "778                 True            True            False         False   \n",
       "789                 True            True             True         False   \n",
       "794                 True            True            False         False   \n",
       "816                 True            True            False         False   \n",
       "843                 True            True            False         False   \n",
       "855                 True            True            False         False   \n",
       "\n",
       "     prediction  \n",
       "236        True  \n",
       "253        True  \n",
       "262        True  \n",
       "289        True  \n",
       "309        True  \n",
       "339        True  \n",
       "361        True  \n",
       "379        True  \n",
       "438        True  \n",
       "464        True  \n",
       "550        True  \n",
       "588        True  \n",
       "747        True  \n",
       "763        True  \n",
       "778        True  \n",
       "789        True  \n",
       "794        True  \n",
       "816        True  \n",
       "843        True  \n",
       "855        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">identifier</th>\n",
       "      <th colspan=\"2\" halign=\"left\">length_ok</th>\n",
       "      <th colspan=\"2\" halign=\"left\">capital_first_token</th>\n",
       "      <th colspan=\"2\" halign=\"left\">not_period_end</th>\n",
       "      <th colspan=\"2\" halign=\"left\">imperative_mood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th>good_message</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <td>4586</td>\n",
       "      <td>2275</td>\n",
       "      <td>4586</td>\n",
       "      <td>4586</td>\n",
       "      <td>4586</td>\n",
       "      <td>4586</td>\n",
       "      <td>4586</td>\n",
       "      <td>4586</td>\n",
       "      <td>4586</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        identifier       length_ok       capital_first_token  \\\n",
       "                             count   sum     count   sum               count   \n",
       "prediction good_message                                                        \n",
       "True       False              4586  2275      4586  4586                4586   \n",
       "\n",
       "                              not_period_end       imperative_mood       \n",
       "                          sum          count   sum           count  sum  \n",
       "prediction good_message                                                  \n",
       "True       False         4586           4586  4586            4586  538  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(FP_samples.head(20))\n",
    "FP_samples.groupby([\"prediction\", \"good_message\"]) \\\n",
    "    .agg({\"identifier\": [\"count\", \"sum\"], \\\n",
    "          \"length_ok\": [\"count\", \"sum\"], \\\n",
    "          \"capital_first_token\": [\"count\", \"sum\"], \\\n",
    "          \"not_period_end\": [\"count\", \"sum\"], \\\n",
    "          \"imperative_mood\": [\"count\", \"sum\"]}) \\\n",
    "    .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4586, 12)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_samples.loc[(FP_samples.length_ok == True) & (FP_samples.capital_first_token == True) & (FP_samples.not_period_end == True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>first_segment_message</th>\n",
       "      <th>identifier</th>\n",
       "      <th>length_ok</th>\n",
       "      <th>capital_first_token</th>\n",
       "      <th>not_period_end</th>\n",
       "      <th>imperative_mood</th>\n",
       "      <th>good_message</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>swong001</td>\n",
       "      <td>1377738900</td>\n",
       "      <td>Update create_spring_mvc.sh</td>\n",
       "      <td>Update create_spring_mvc.sh\\n\\nUsing heredoc c...</td>\n",
       "      <td>Update create_spring_mvc.sh</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pablo de la Peña</td>\n",
       "      <td>1421086410</td>\n",
       "      <td>Mminor update to core proxy classes</td>\n",
       "      <td>Mminor update to core proxy classes\\n</td>\n",
       "      <td>Mminor update to core proxy classes\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Simon Edwards</td>\n",
       "      <td>1550181413</td>\n",
       "      <td>Update the node-sass binary. (win32)</td>\n",
       "      <td>Update the node-sass binary. (win32)\\n</td>\n",
       "      <td>Update the node-sass binary. (win32)\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Grant Likely</td>\n",
       "      <td>1454496242</td>\n",
       "      <td>Fix typo on 'cell' definition</td>\n",
       "      <td>Fix typo on 'cell' definition\\n\\nSigned-off-by...</td>\n",
       "      <td>Fix typo on 'cell' definition</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Teresa Lynn</td>\n",
       "      <td>1431691902</td>\n",
       "      <td>Update list.md</td>\n",
       "      <td>Update list.md</td>\n",
       "      <td>Update list.md</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>A. Diamond</td>\n",
       "      <td>1540842090</td>\n",
       "      <td>Updated APTrust test bag readme</td>\n",
       "      <td>Updated APTrust test bag readme\\n</td>\n",
       "      <td>Updated APTrust test bag readme\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>jakewhite1230</td>\n",
       "      <td>1464738735</td>\n",
       "      <td>Enhanced the Front Page and Added new Widget</td>\n",
       "      <td>Enhanced the Front Page and Added new Widget\\n...</td>\n",
       "      <td>Enhanced the Front Page and Added new Widget</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Lucas Doyle</td>\n",
       "      <td>1413298129</td>\n",
       "      <td>Update scoring.md</td>\n",
       "      <td>Update scoring.md</td>\n",
       "      <td>Update scoring.md</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Yuki Hattori</td>\n",
       "      <td>1455120365</td>\n",
       "      <td>Implement #9: Supports opening file by D&amp;D</td>\n",
       "      <td>Implement #9: Supports opening file by D&amp;D\\n</td>\n",
       "      <td>Implement #9: Supports opening file by D&amp;D\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>1500966737</td>\n",
       "      <td>Update readme (#5)</td>\n",
       "      <td>Update readme (#5)\\n\\n* Updates port\\r\\n\\r\\n* ...</td>\n",
       "      <td>Update readme (#5)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>James Cox</td>\n",
       "      <td>1376900176</td>\n",
       "      <td>Delete tests which are run on the server</td>\n",
       "      <td>Delete tests which are run on the server\\n</td>\n",
       "      <td>Delete tests which are run on the server\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>1538563620</td>\n",
       "      <td>Merge pull request #573 from alphagov/ris-av-t...</td>\n",
       "      <td>Merge pull request #573 from alphagov/ris-av-t...</td>\n",
       "      <td>Merge pull request #573 from alphagov/ris-av-t...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>Petey101</td>\n",
       "      <td>1450313664</td>\n",
       "      <td>Update my-berkshire-stylesheet.css</td>\n",
       "      <td>Update my-berkshire-stylesheet.css</td>\n",
       "      <td>Update my-berkshire-stylesheet.css</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>jdcoffre</td>\n",
       "      <td>1400506627</td>\n",
       "      <td>Refactor project packages</td>\n",
       "      <td>Refactor project packages\\n</td>\n",
       "      <td>Refactor project packages\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Hui</td>\n",
       "      <td>1452082645</td>\n",
       "      <td>Update got.c</td>\n",
       "      <td>Update got.c</td>\n",
       "      <td>Update got.c</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Ivan Nikolić</td>\n",
       "      <td>1547454927</td>\n",
       "      <td>Improve Karma testing tooling</td>\n",
       "      <td>Improve Karma testing tooling\\n</td>\n",
       "      <td>Improve Karma testing tooling\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>DJ_Kovrik</td>\n",
       "      <td>1516473558</td>\n",
       "      <td>Code style formatting</td>\n",
       "      <td>Code style formatting\\n</td>\n",
       "      <td>Code style formatting\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>Thomas Sødring</td>\n",
       "      <td>1496317391</td>\n",
       "      <td>Update methods to make them null safe</td>\n",
       "      <td>Update methods to make them null safe\\n</td>\n",
       "      <td>Update methods to make them null safe\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>Marc-André Goyette</td>\n",
       "      <td>1472311075</td>\n",
       "      <td>Update tasks list</td>\n",
       "      <td>Update tasks list\\n</td>\n",
       "      <td>Update tasks list\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>1468369963</td>\n",
       "      <td>Update big data</td>\n",
       "      <td>Update big data</td>\n",
       "      <td>Update big data</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name    time_sec  \\\n",
       "24              swong001  1377738900   \n",
       "35     Pablo de la Peña  1421086410   \n",
       "145        Simon Edwards  1550181413   \n",
       "511         Grant Likely  1454496242   \n",
       "570          Teresa Lynn  1431691902   \n",
       "684           A. Diamond  1540842090   \n",
       "891        jakewhite1230  1464738735   \n",
       "1094         Lucas Doyle  1413298129   \n",
       "1220        Yuki Hattori  1455120365   \n",
       "1438              GitHub  1500966737   \n",
       "1519           James Cox  1376900176   \n",
       "1619              GitHub  1538563620   \n",
       "1635            Petey101  1450313664   \n",
       "1732            jdcoffre  1400506627   \n",
       "1755                 Hui  1452082645   \n",
       "1784        Ivan Nikolić  1547454927   \n",
       "1847           DJ_Kovrik  1516473558   \n",
       "1890      Thomas Sødring  1496317391   \n",
       "2079  Marc-André Goyette  1472311075   \n",
       "2286              GitHub  1468369963   \n",
       "\n",
       "                                                subject  \\\n",
       "24                          Update create_spring_mvc.sh   \n",
       "35                  Mminor update to core proxy classes   \n",
       "145                Update the node-sass binary. (win32)   \n",
       "511                       Fix typo on 'cell' definition   \n",
       "570                                      Update list.md   \n",
       "684                     Updated APTrust test bag readme   \n",
       "891        Enhanced the Front Page and Added new Widget   \n",
       "1094                                  Update scoring.md   \n",
       "1220         Implement #9: Supports opening file by D&D   \n",
       "1438                                 Update readme (#5)   \n",
       "1519           Delete tests which are run on the server   \n",
       "1619  Merge pull request #573 from alphagov/ris-av-t...   \n",
       "1635                 Update my-berkshire-stylesheet.css   \n",
       "1732                          Refactor project packages   \n",
       "1755                                       Update got.c   \n",
       "1784                      Improve Karma testing tooling   \n",
       "1847                              Code style formatting   \n",
       "1890              Update methods to make them null safe   \n",
       "2079                                  Update tasks list   \n",
       "2286                                    Update big data   \n",
       "\n",
       "                                                message  \\\n",
       "24    Update create_spring_mvc.sh\\n\\nUsing heredoc c...   \n",
       "35                Mminor update to core proxy classes\\n   \n",
       "145              Update the node-sass binary. (win32)\\n   \n",
       "511   Fix typo on 'cell' definition\\n\\nSigned-off-by...   \n",
       "570                                      Update list.md   \n",
       "684                   Updated APTrust test bag readme\\n   \n",
       "891   Enhanced the Front Page and Added new Widget\\n...   \n",
       "1094                                  Update scoring.md   \n",
       "1220       Implement #9: Supports opening file by D&D\\n   \n",
       "1438  Update readme (#5)\\n\\n* Updates port\\r\\n\\r\\n* ...   \n",
       "1519         Delete tests which are run on the server\\n   \n",
       "1619  Merge pull request #573 from alphagov/ris-av-t...   \n",
       "1635                 Update my-berkshire-stylesheet.css   \n",
       "1732                        Refactor project packages\\n   \n",
       "1755                                       Update got.c   \n",
       "1784                    Improve Karma testing tooling\\n   \n",
       "1847                            Code style formatting\\n   \n",
       "1890            Update methods to make them null safe\\n   \n",
       "2079                                Update tasks list\\n   \n",
       "2286                                    Update big data   \n",
       "\n",
       "                                  first_segment_message  identifier  \\\n",
       "24                          Update create_spring_mvc.sh        True   \n",
       "35                Mminor update to core proxy classes\\n        True   \n",
       "145              Update the node-sass binary. (win32)\\n        True   \n",
       "511                       Fix typo on 'cell' definition        True   \n",
       "570                                      Update list.md        True   \n",
       "684                   Updated APTrust test bag readme\\n        True   \n",
       "891        Enhanced the Front Page and Added new Widget        True   \n",
       "1094                                  Update scoring.md        True   \n",
       "1220       Implement #9: Supports opening file by D&D\\n        True   \n",
       "1438                                 Update readme (#5)        True   \n",
       "1519         Delete tests which are run on the server\\n        True   \n",
       "1619  Merge pull request #573 from alphagov/ris-av-t...        True   \n",
       "1635                 Update my-berkshire-stylesheet.css        True   \n",
       "1732                        Refactor project packages\\n        True   \n",
       "1755                                       Update got.c        True   \n",
       "1784                    Improve Karma testing tooling\\n        True   \n",
       "1847                            Code style formatting\\n        True   \n",
       "1890            Update methods to make them null safe\\n        True   \n",
       "2079                                Update tasks list\\n        True   \n",
       "2286                                    Update big data        True   \n",
       "\n",
       "      length_ok  capital_first_token  not_period_end  imperative_mood  \\\n",
       "24         True                 True            True             True   \n",
       "35         True                 True            True             True   \n",
       "145        True                 True            True             True   \n",
       "511        True                 True            True             True   \n",
       "570        True                 True            True             True   \n",
       "684        True                 True            True             True   \n",
       "891        True                 True            True             True   \n",
       "1094       True                 True            True             True   \n",
       "1220       True                 True            True             True   \n",
       "1438       True                 True            True             True   \n",
       "1519       True                 True            True             True   \n",
       "1619       True                 True            True             True   \n",
       "1635       True                 True            True             True   \n",
       "1732       True                 True            True             True   \n",
       "1755       True                 True            True             True   \n",
       "1784       True                 True            True             True   \n",
       "1847       True                 True            True             True   \n",
       "1890       True                 True            True             True   \n",
       "2079       True                 True            True             True   \n",
       "2286       True                 True            True             True   \n",
       "\n",
       "      good_message  prediction  \n",
       "24            True       False  \n",
       "35            True       False  \n",
       "145           True       False  \n",
       "511           True       False  \n",
       "570           True       False  \n",
       "684           True       False  \n",
       "891           True       False  \n",
       "1094          True       False  \n",
       "1220          True       False  \n",
       "1438          True       False  \n",
       "1519          True       False  \n",
       "1619          True       False  \n",
       "1635          True       False  \n",
       "1732          True       False  \n",
       "1755          True       False  \n",
       "1784          True       False  \n",
       "1847          True       False  \n",
       "1890          True       False  \n",
       "2079          True       False  \n",
       "2286          True       False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">identifier</th>\n",
       "      <th colspan=\"2\" halign=\"left\">length_ok</th>\n",
       "      <th colspan=\"2\" halign=\"left\">capital_first_token</th>\n",
       "      <th colspan=\"2\" halign=\"left\">not_period_end</th>\n",
       "      <th colspan=\"2\" halign=\"left\">imperative_mood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th>good_message</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "      <td>3831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        identifier       length_ok       capital_first_token  \\\n",
       "                             count   sum     count   sum               count   \n",
       "prediction good_message                                                        \n",
       "False      True               3831  3831      3831  3831                3831   \n",
       "\n",
       "                              not_period_end       imperative_mood        \n",
       "                          sum          count   sum           count   sum  \n",
       "prediction good_message                                                   \n",
       "False      True          3831           3831  3831            3831  3831  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(FN_samples.head(20))\n",
    "FN_samples.groupby([\"prediction\", \"good_message\"]) \\\n",
    "    .agg({\"identifier\": [\"count\", \"sum\"], \\\n",
    "          \"length_ok\": [\"count\", \"sum\"], \\\n",
    "          \"capital_first_token\": [\"count\", \"sum\"], \\\n",
    "          \"not_period_end\": [\"count\", \"sum\"], \\\n",
    "          \"imperative_mood\": [\"count\", \"sum\"]}) \\\n",
    "    .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
